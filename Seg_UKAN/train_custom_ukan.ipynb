{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc8144e",
   "metadata": {},
   "source": [
    "# U-KAN Training for Custom Segmentation Dataset\n",
    "\n",
    "This notebook demonstrates how to train U-KAN for medical image segmentation using your custom dataset structure:\n",
    "- train/images (.jpg)\n",
    "- train/masks (.png)\n",
    "- val/images (.jpg) \n",
    "- val/masks (.png)\n",
    "- test/images (.jpg) - for prediction only\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad971c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Albumentations for data augmentation\n",
    "from albumentations.augmentations import transforms\n",
    "from albumentations.augmentations import geometric\n",
    "from albumentations.core.composition import Compose\n",
    "from albumentations import RandomRotate90, Resize\n",
    "\n",
    "# Model imports\n",
    "import archs\n",
    "import losses\n",
    "from custom_dataset import CustomDataset\n",
    "from metrics import iou_score, indicators\n",
    "from utils import AverageMeter, str2bool\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd3f85e",
   "metadata": {},
   "source": [
    "## Configuration and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    # Data paths\n",
    "    'train_img_dir': './data/train/images',\n",
    "    'train_mask_dir': './data/train/masks', \n",
    "    'val_img_dir': './data/val/images',\n",
    "    'val_mask_dir': './data/val/masks',\n",
    "    'test_img_dir': './data/test/images',\n",
    "    'output_dir': './outputs',\n",
    "    'experiment_name': 'custom_ukan_experiment',\n",
    "    \n",
    "    # Model parameters\n",
    "    'arch': 'UKAN',\n",
    "    'num_classes': 1,\n",
    "    'input_channels': 3,\n",
    "    'deep_supervision': False,\n",
    "    'input_w': 256,\n",
    "    'input_h': 256,\n",
    "    'embed_dims': [256, 320, 512],\n",
    "    'no_kan': False,  # Set to True to use MLP instead of KAN\n",
    "    \n",
    "    # Training parameters\n",
    "    'epochs': 100,\n",
    "    'batch_size': 8,\n",
    "    'lr': 1e-4,\n",
    "    'kan_lr': 1e-2,\n",
    "    'weight_decay': 1e-4,\n",
    "    'kan_weight_decay': 1e-4,\n",
    "    'num_workers': 4,\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    'loss': 'BCEDiceLoss',\n",
    "    'optimizer': 'Adam',\n",
    "    \n",
    "    # Scheduler\n",
    "    'scheduler': 'CosineAnnealingLR',\n",
    "    'min_lr': 1e-5,\n",
    "    \n",
    "    # Early stopping\n",
    "    'early_stopping': 20,\n",
    "    'save_best_only': True\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed85c874",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    \"\"\"Set seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def create_dir(path):\n",
    "    \"\"\"Create directory if it doesn't exist\"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def save_config(config, save_path):\n",
    "    \"\"\"Save configuration to yaml file\"\"\"\n",
    "    with open(save_path, 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed_everything(42)\n",
    "\n",
    "# Create output directory\n",
    "exp_dir = os.path.join(config['output_dir'], config['experiment_name'])\n",
    "create_dir(exp_dir)\n",
    "\n",
    "# Save configuration\n",
    "save_config(config, os.path.join(exp_dir, 'config.yaml'))\n",
    "print(f\"Experiment directory: {exp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f60461",
   "metadata": {},
   "source": [
    "## Data Loading and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842467c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transforms\n",
    "train_transform = Compose([\n",
    "    RandomRotate90(),\n",
    "    geometric.transforms.Flip(),\n",
    "    Resize(config['input_h'], config['input_w']),\n",
    "    transforms.Normalize(),\n",
    "])\n",
    "\n",
    "val_transform = Compose([\n",
    "    Resize(config['input_h'], config['input_w']),\n",
    "    transforms.Normalize(),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(\n",
    "    img_dir=config['train_img_dir'],\n",
    "    mask_dir=config['train_mask_dir'],\n",
    "    transform=train_transform,\n",
    "    is_test=False\n",
    ")\n",
    "\n",
    "val_dataset = CustomDataset(\n",
    "    img_dir=config['val_img_dir'],\n",
    "    mask_dir=config['val_mask_dir'],\n",
    "    transform=val_transform,\n",
    "    is_test=False\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['num_workers'],\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5737a4c7",
   "metadata": {},
   "source": [
    "## Model, Loss, and Optimizer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70459902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = archs.UKAN(\n",
    "    num_classes=config['num_classes'],\n",
    "    input_channels=config['input_channels'],\n",
    "    deep_supervision=config['deep_supervision'],\n",
    "    embed_dims=config['embed_dims'],\n",
    "    no_kan=config['no_kan']\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Define loss function\n",
    "if config['loss'] == 'BCEWithLogitsLoss':\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "else:\n",
    "    criterion = getattr(losses, config['loss'])().to(device)\n",
    "\n",
    "# Setup optimizer with different learning rates for KAN and other parameters\n",
    "param_groups = []\n",
    "for name, param in model.named_parameters():\n",
    "    if 'layer' in name.lower() and 'fc' in name.lower():  # KAN layers\n",
    "        param_groups.append({\n",
    "            'params': param, \n",
    "            'lr': config['kan_lr'], \n",
    "            'weight_decay': config['kan_weight_decay']\n",
    "        })\n",
    "    else:  # Other parameters\n",
    "        param_groups.append({\n",
    "            'params': param, \n",
    "            'lr': config['lr'], \n",
    "            'weight_decay': config['weight_decay']\n",
    "        })\n",
    "\n",
    "optimizer = optim.Adam(param_groups)\n",
    "\n",
    "# Setup scheduler\n",
    "if config['scheduler'] == 'CosineAnnealingLR':\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=config['epochs'], eta_min=config['min_lr']\n",
    "    )\n",
    "else:\n",
    "    scheduler = None\n",
    "\n",
    "print(\"Model, loss, optimizer, and scheduler initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db612d24",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    ious = AverageMeter()\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    for batch_idx, (images, masks, meta) in enumerate(pbar):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        if config['deep_supervision']:\n",
    "            outputs = model(images)\n",
    "            loss = 0\n",
    "            for output in outputs:\n",
    "                loss += criterion(output, masks)\n",
    "            loss /= len(outputs)\n",
    "            iou, dice, _ = iou_score(outputs[-1], masks)\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            iou, dice, _ = iou_score(outputs, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        ious.update(iou, images.size(0))\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{losses.avg:.4f}',\n",
    "            'IoU': f'{ious.avg:.4f}'\n",
    "        })\n",
    "    \n",
    "    return {'loss': losses.avg, 'iou': ious.avg}\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    ious = AverageMeter()\n",
    "    dices = AverageMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc='Validation')\n",
    "        for batch_idx, (images, masks, meta) in enumerate(pbar):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            if config['deep_supervision']:\n",
    "                outputs = model(images)\n",
    "                loss = 0\n",
    "                for output in outputs:\n",
    "                    loss += criterion(output, masks)\n",
    "                loss /= len(outputs)\n",
    "                iou, dice, _ = iou_score(outputs[-1], masks)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                iou, dice, _ = iou_score(outputs, masks)\n",
    "            \n",
    "            # Update metrics\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            ious.update(iou, images.size(0))\n",
    "            dices.update(dice, images.size(0))\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{losses.avg:.4f}',\n",
    "                'IoU': f'{ious.avg:.4f}',\n",
    "                'Dice': f'{dices.avg:.4f}'\n",
    "            })\n",
    "    \n",
    "    return {'loss': losses.avg, 'iou': ious.avg, 'dice': dices.avg}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6192cf18",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34449ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training variables\n",
    "best_iou = 0.0\n",
    "best_dice = 0.0\n",
    "patience_counter = 0\n",
    "train_history = {'epoch': [], 'train_loss': [], 'train_iou': [], 'val_loss': [], 'val_iou': [], 'val_dice': []}\n",
    "\n",
    "# Setup tensorboard writer\n",
    "writer = SummaryWriter(os.path.join(exp_dir, 'tensorboard'))\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print(f\"Epoch [{epoch+1}/{config['epochs']}]\")\n",
    "    \n",
    "    # Train\n",
    "    train_metrics = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_metrics = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Log metrics\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"LR: {current_lr:.6f} | \"\n",
    "          f\"Train Loss: {train_metrics['loss']:.4f} | \"\n",
    "          f\"Train IoU: {train_metrics['iou']:.4f} | \"\n",
    "          f\"Val Loss: {val_metrics['loss']:.4f} | \"\n",
    "          f\"Val IoU: {val_metrics['iou']:.4f} | \"\n",
    "          f\"Val Dice: {val_metrics['dice']:.4f}\")\n",
    "    \n",
    "    # Save to history\n",
    "    train_history['epoch'].append(epoch + 1)\n",
    "    train_history['train_loss'].append(train_metrics['loss'])\n",
    "    train_history['train_iou'].append(train_metrics['iou'])\n",
    "    train_history['val_loss'].append(val_metrics['loss'])\n",
    "    train_history['val_iou'].append(val_metrics['iou'])\n",
    "    train_history['val_dice'].append(val_metrics['dice'])\n",
    "    \n",
    "    # Write to tensorboard\n",
    "    writer.add_scalar('Train/Loss', train_metrics['loss'], epoch)\n",
    "    writer.add_scalar('Train/IoU', train_metrics['iou'], epoch)\n",
    "    writer.add_scalar('Val/Loss', val_metrics['loss'], epoch)\n",
    "    writer.add_scalar('Val/IoU', val_metrics['iou'], epoch)\n",
    "    writer.add_scalar('Val/Dice', val_metrics['dice'], epoch)\n",
    "    writer.add_scalar('Learning_Rate', current_lr, epoch)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_metrics['iou'] > best_iou:\n",
    "        best_iou = val_metrics['iou']\n",
    "        best_dice = val_metrics['dice']\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Save best model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_iou': best_iou,\n",
    "            'best_dice': best_dice,\n",
    "            'config': config\n",
    "        }, os.path.join(exp_dir, 'best_model.pth'))\n",
    "        \n",
    "        print(f\"★ New best model saved! IoU: {best_iou:.4f}, Dice: {best_dice:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= config['early_stopping']:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Save final model\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_history': train_history,\n",
    "    'config': config\n",
    "}, os.path.join(exp_dir, 'final_model.pth'))\n",
    "\n",
    "# Save training history\n",
    "pd.DataFrame(train_history).to_csv(os.path.join(exp_dir, 'training_history.csv'), index=False)\n",
    "\n",
    "writer.close()\n",
    "print(f\"Training completed! Best IoU: {best_iou:.4f}, Best Dice: {best_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84b13c6",
   "metadata": {},
   "source": [
    "## Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9e5695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss plot\n",
    "axes[0, 0].plot(train_history['epoch'], train_history['train_loss'], label='Train Loss', color='blue')\n",
    "axes[0, 0].plot(train_history['epoch'], train_history['val_loss'], label='Val Loss', color='red')\n",
    "axes[0, 0].set_title('Training and Validation Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# IoU plot\n",
    "axes[0, 1].plot(train_history['epoch'], train_history['train_iou'], label='Train IoU', color='blue')\n",
    "axes[0, 1].plot(train_history['epoch'], train_history['val_iou'], label='Val IoU', color='red')\n",
    "axes[0, 1].set_title('Training and Validation IoU')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('IoU')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Dice plot\n",
    "axes[1, 0].plot(train_history['epoch'], train_history['val_dice'], label='Val Dice', color='green')\n",
    "axes[1, 0].set_title('Validation Dice Score')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Dice')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Combined metrics\n",
    "axes[1, 1].plot(train_history['epoch'], train_history['val_iou'], label='Val IoU', color='red')\n",
    "axes[1, 1].plot(train_history['epoch'], train_history['val_dice'], label='Val Dice', color='green')\n",
    "axes[1, 1].set_title('Validation Metrics')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Score')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(exp_dir, 'training_curves.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print final results\n",
    "print(\"=\"*50)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best Validation IoU: {best_iou:.4f}\")\n",
    "print(f\"Best Validation Dice: {best_dice:.4f}\")\n",
    "print(f\"Total Epochs: {len(train_history['epoch'])}\")\n",
    "print(f\"Experiment Directory: {exp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf3fc22",
   "metadata": {},
   "source": [
    "## Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82393828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_data(model_path, test_img_dir, output_dir, config):\n",
    "    \"\"\"Predict on test data and save results\"\"\"\n",
    "    \n",
    "    # Load best model\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model = archs.UKAN(\n",
    "        num_classes=config['num_classes'],\n",
    "        input_channels=config['input_channels'],\n",
    "        deep_supervision=config['deep_supervision'],\n",
    "        embed_dims=config['embed_dims'],\n",
    "        no_kan=config['no_kan']\n",
    "    )\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Create test dataset\n",
    "    test_dataset = CustomDataset(\n",
    "        img_dir=test_img_dir,\n",
    "        mask_dir=None,\n",
    "        transform=val_transform,\n",
    "        is_test=True\n",
    "    )\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=1,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    # Create output directory\n",
    "    create_dir(output_dir)\n",
    "    \n",
    "    print(f\"Predicting on {len(test_dataset)} test images...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, _, meta) in enumerate(tqdm(test_loader, desc='Predicting')):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            if config['deep_supervision']:\n",
    "                outputs = model(images)\n",
    "                output = outputs[-1]\n",
    "            else:\n",
    "                output = model(images)\n",
    "            \n",
    "            # Apply sigmoid and threshold\n",
    "            pred = torch.sigmoid(output).cpu().numpy()\n",
    "            pred = (pred >= 0.5).astype(np.uint8)\n",
    "            \n",
    "            # Save prediction\n",
    "            img_id = meta['img_id'][0]\n",
    "            pred_mask = pred[0, 0]  # Remove batch and channel dimensions\n",
    "            pred_mask = pred_mask * 255  # Convert to 0-255 range\n",
    "            \n",
    "            # Save as PNG\n",
    "            output_path = os.path.join(output_dir, f\"{img_id}_pred.png\")\n",
    "            Image.fromarray(pred_mask, mode='L').save(output_path)\n",
    "    \n",
    "    print(f\"Predictions saved to: {output_dir}\")\n",
    "\n",
    "# Run prediction on test data\n",
    "test_output_dir = os.path.join(exp_dir, 'test_predictions')\n",
    "best_model_path = os.path.join(exp_dir, 'best_model.pth')\n",
    "\n",
    "if os.path.exists(config['test_img_dir']) and os.path.exists(best_model_path):\n",
    "    predict_test_data(best_model_path, config['test_img_dir'], test_output_dir, config)\n",
    "else:\n",
    "    print(\"Test images directory or best model not found. Skipping prediction.\")\n",
    "    if not os.path.exists(config['test_img_dir']):\n",
    "        print(f\"Test directory not found: {config['test_img_dir']}\")\n",
    "    if not os.path.exists(best_model_path):\n",
    "        print(f\"Best model not found: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15522dac",
   "metadata": {},
   "source": [
    "## Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bdb1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(val_img_dir, val_mask_dir, model_path, config, num_samples=5):\n",
    "    \"\"\"Visualize predictions on validation data\"\"\"\n",
    "    \n",
    "    # Load model\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model = archs.UKAN(\n",
    "        num_classes=config['num_classes'],\n",
    "        input_channels=config['input_channels'],\n",
    "        deep_supervision=config['deep_supervision'],\n",
    "        embed_dims=config['embed_dims'],\n",
    "        no_kan=config['no_kan']\n",
    "    )\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Create validation dataset\n",
    "    val_vis_dataset = CustomDataset(\n",
    "        img_dir=val_img_dir,\n",
    "        mask_dir=val_mask_dir,\n",
    "        transform=val_transform,\n",
    "        is_test=False\n",
    "    )\n",
    "    \n",
    "    # Randomly sample images\n",
    "    indices = random.sample(range(len(val_vis_dataset)), min(num_samples, len(val_vis_dataset)))\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate(indices):\n",
    "            image, mask, meta = val_vis_dataset[idx]\n",
    "            img_id = meta['img_id']\n",
    "            \n",
    "            # Add batch dimension and predict\n",
    "            image_batch = image.unsqueeze(0).to(device)\n",
    "            \n",
    "            if config['deep_supervision']:\n",
    "                outputs = model(image_batch)\n",
    "                output = outputs[-1]\n",
    "            else:\n",
    "                output = model(image_batch)\n",
    "            \n",
    "            pred = torch.sigmoid(output).cpu().numpy()[0, 0]\n",
    "            pred_binary = (pred >= 0.5).astype(np.uint8)\n",
    "            \n",
    "            # Convert for visualization\n",
    "            img_vis = image.permute(1, 2, 0).numpy()\n",
    "            img_vis = (img_vis - img_vis.min()) / (img_vis.max() - img_vis.min())\n",
    "            \n",
    "            mask_vis = mask[0].numpy()\n",
    "            \n",
    "            # Plot\n",
    "            axes[i, 0].imshow(img_vis)\n",
    "            axes[i, 0].set_title(f'Original Image\\n{img_id}')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            axes[i, 1].imshow(mask_vis, cmap='gray')\n",
    "            axes[i, 1].set_title('Ground Truth')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            axes[i, 2].imshow(pred_binary, cmap='gray')\n",
    "            axes[i, 2].set_title('Prediction')\n",
    "            axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(exp_dir, 'validation_predictions.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some validation predictions\n",
    "if os.path.exists(best_model_path):\n",
    "    visualize_predictions(\n",
    "        config['val_img_dir'], \n",
    "        config['val_mask_dir'], \n",
    "        best_model_path, \n",
    "        config, \n",
    "        num_samples=3\n",
    "    )\n",
    "else:\n",
    "    print(\"Best model not found for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048dc5c1",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "The training is now complete! Here's what was accomplished:\n",
    "\n",
    "1. **Model Training**: Trained U-KAN on your custom dataset\n",
    "2. **Validation**: Monitored performance on validation set\n",
    "3. **Best Model**: Saved the best performing model based on IoU score\n",
    "4. **Test Prediction**: Generated predictions for test images\n",
    "5. **Visualization**: Created training curves and sample predictions\n",
    "\n",
    "### Output Files:\n",
    "- `best_model.pth`: Best performing model weights\n",
    "- `final_model.pth`: Final model weights\n",
    "- `training_history.csv`: Training metrics log\n",
    "- `training_curves.png`: Training progress visualization\n",
    "- `test_predictions/`: Folder containing test predictions\n",
    "- `validation_predictions.png`: Sample validation results\n",
    "- `config.yaml`: Training configuration\n",
    "\n",
    "### To use the trained model:\n",
    "1. Load the best model using `torch.load('best_model.pth')`\n",
    "2. Use the prediction function to segment new images\n",
    "3. Adjust threshold (0.5) based on your specific needs\n",
    "\n",
    "### Tips for better performance:\n",
    "- Increase training epochs if loss is still decreasing\n",
    "- Experiment with different learning rates\n",
    "- Try data augmentation techniques\n",
    "- Use larger input resolution if computationally feasible\n",
    "- Consider ensemble methods for final predictions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
